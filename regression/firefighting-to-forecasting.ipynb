{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb80ebee-b4d5-454b-a194-1941fc4eafc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate timestamps for 3 months of data at 5-minute intervals\n",
    "start_date = datetime(2023, 9, 1)\n",
    "end_date = datetime(2023, 12, 1)\n",
    "timestamps = pd.date_range(start=start_date, end=end_date, freq='5T')\n",
    "\n",
    "# Initialize lists to store our data\n",
    "data = []\n",
    "\n",
    "# Common API endpoints\n",
    "endpoints = [\n",
    "    '/api/v1/users',\n",
    "    '/api/v1/products',\n",
    "    '/api/v1/orders',\n",
    "    '/api/v1/cart',\n",
    "    '/api/v1/checkout'\n",
    "]\n",
    "\n",
    "# Define baseline metrics for each endpoint\n",
    "endpoint_baselines = {\n",
    "    '/api/v1/users': {'latency': 150, 'error_rate': 0.02},\n",
    "    '/api/v1/products': {'latency': 200, 'error_rate': 0.01},\n",
    "    '/api/v1/orders': {'latency': 300, 'error_rate': 0.03},\n",
    "    '/api/v1/cart': {'latency': 100, 'error_rate': 0.01},\n",
    "    '/api/v1/checkout': {'latency': 400, 'error_rate': 0.04}\n",
    "}\n",
    "\n",
    "# Generate data for each timestamp\n",
    "for ts in timestamps:\n",
    "    # Add daily and weekly patterns\n",
    "    hour_factor = 1 + 0.3 * np.sin(2 * np.pi * ts.hour / 24)  # Daily pattern\n",
    "    day_factor = 1 + 0.2 * np.sin(2 * np.pi * ts.dayofweek / 7)  # Weekly pattern\n",
    "    \n",
    "    for endpoint in endpoints:\n",
    "        baseline = endpoint_baselines[endpoint]\n",
    "        \n",
    "        # Calculate requests per 5-minute interval\n",
    "        base_requests = np.random.normal(1000, 100) * hour_factor * day_factor\n",
    "        requests = max(int(base_requests), 0)\n",
    "        \n",
    "        # Calculate latency with realistic variations\n",
    "        base_latency = baseline['latency']\n",
    "        latency = max(\n",
    "            np.random.normal(\n",
    "                base_latency * hour_factor,\n",
    "                base_latency * 0.1\n",
    "            ), \n",
    "            10\n",
    "        )\n",
    "        \n",
    "        # Calculate error rate with slight randomness\n",
    "        base_error_rate = baseline['error_rate']\n",
    "        error_rate = max(min(\n",
    "            np.random.normal(\n",
    "                base_error_rate * hour_factor,\n",
    "                base_error_rate * 0.2\n",
    "            ),\n",
    "            1.0\n",
    "        ), 0.0)\n",
    "        \n",
    "        # Calculate errors\n",
    "        errors = int(requests * error_rate)\n",
    "        \n",
    "        # Calculate CPU and memory utilization\n",
    "        cpu_util = min(\n",
    "            max(\n",
    "                np.random.normal(60, 10) * hour_factor * day_factor, \n",
    "                0\n",
    "            ), \n",
    "            100\n",
    "        )\n",
    "        memory_util = min(\n",
    "            max(\n",
    "                np.random.normal(70, 5) * hour_factor,\n",
    "                0\n",
    "            ),\n",
    "            100\n",
    "        )\n",
    "\n",
    "        data.append({\n",
    "            'timestamp': ts,\n",
    "            'endpoint': endpoint,\n",
    "            'requests': requests,\n",
    "            'latency_ms': round(latency, 2),\n",
    "            'errors': errors,\n",
    "            'error_rate': round(error_rate * 100, 2),\n",
    "            'cpu_utilization': round(cpu_util, 2),\n",
    "            'memory_utilization': round(memory_util, 2)\n",
    "        })\n",
    "\n",
    "# Create DataFrame and sort by timestamp\n",
    "df = pd.DataFrame(data)\n",
    "df = df.sort_values('timestamp')\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('api_performance_data.csv', index=False)\n",
    "\n",
    "# Display a sample of the data with better formatting\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Create a proper copy of the first 15 rows\n",
    "sample_df = df.head(15).copy()\n",
    "\n",
    "# Format the data\n",
    "sample_df['timestamp'] = pd.to_datetime(sample_df['timestamp']).dt.strftime('%Y-%m-%d %H:%M')\n",
    "sample_df['requests'] = sample_df['requests'].apply(lambda x: f\"{x:,}\")\n",
    "sample_df['latency_ms'] = sample_df['latency_ms'].round(1)\n",
    "sample_df['error_rate'] = sample_df['error_rate'].round(2)\n",
    "sample_df['cpu_utilization'] = sample_df['cpu_utilization'].round(1)\n",
    "sample_df['memory_utilization'] = sample_df['memory_utilization'].round(1)\n",
    "\n",
    "# Create the table\n",
    "fig = go.Figure(data=[go.Table(\n",
    "    header=dict(\n",
    "        values=['<b>Timestamp</b>', '<b>Endpoint</b>', '<b>Requests</b>', \n",
    "                '<b>Latency (ms)</b>', '<b>Errors</b>', '<b>Error Rate (%)</b>',\n",
    "                '<b>CPU (%)</b>', '<b>Memory (%)</b>'],\n",
    "        font=dict(size=12, color='rgb(55, 65, 81)'),\n",
    "        fill_color='rgb(244, 246, 248)',\n",
    "        align=['left'] * 8,\n",
    "        height=36\n",
    "    ),\n",
    "    cells=dict(\n",
    "        values=[sample_df[col] for col in sample_df.columns],\n",
    "        font=dict(size=11, color='rgb(75, 85, 99)'),\n",
    "        fill_color='rgb(255, 255, 255)',\n",
    "        align=['left'] * 8,\n",
    "        height=30\n",
    "    )\n",
    ")])\n",
    "\n",
    "# Update layout for a cleaner look\n",
    "fig.update_layout(\n",
    "    width=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    "    paper_bgcolor='rgba(0,0,0,0)'\n",
    ")\n",
    "\n",
    "# Save as PNG with high resolution\n",
    "fig.write_image(\"api_metrics_table.png\", scale=2)\n",
    "\n",
    "# Display in notebook\n",
    "fig.show()\n",
    "# print(\"\\nFirst few rows of our API performance dataset:\")\n",
    "# print(df.head())\n",
    "\n",
    "# print(\"\\nDataset Summary:\")\n",
    "# print(f\"Total number of records: {len(df):,}\")\n",
    "# print(f\"Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "# print(\"\\nUnique endpoints:\")\n",
    "# for endpoint in df['endpoint'].unique():\n",
    "#     print(f\"- {endpoint}\")\n",
    "\n",
    "# # Basic statistics for numerical columns\n",
    "# print(\"\\nBasic statistics for key metrics:\")\n",
    "# print(df[['requests', 'latency_ms', 'error_rate', 'cpu_utilization', 'memory_utilization']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8be7f1-38fe-4bd9-8cc1-6322b33e5241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3d5c8c-b8c5-41b3-8c9f-e416190adc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "\n",
    "def create_daily_pattern(df):\n",
    "    # Convert timestamp to hour\n",
    "    df['hour'] = pd.to_datetime(df['timestamp']).dt.hour\n",
    "    \n",
    "    # Group by hour and calculate means\n",
    "    hourly_stats = df.groupby('hour').agg({\n",
    "        'requests': 'mean',\n",
    "        'latency_ms': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Create figure with secondary y-axis\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "    \n",
    "    # Add traces\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=hourly_stats['hour'], y=hourly_stats['requests'],\n",
    "                  name=\"Requests\", line=dict(color=\"#2E86C1\")),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=hourly_stats['hour'], y=hourly_stats['latency_ms'],\n",
    "                  name=\"Latency (ms)\", line=dict(color=\"#E74C3C\")),\n",
    "        secondary_y=True,\n",
    "    )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=\"24-Hour Traffic Pattern with Latency\",\n",
    "        xaxis_title=\"Hour of Day\",\n",
    "        template=\"plotly_white\",\n",
    "        height=500,\n",
    "        width=800,\n",
    "        font=dict(size=10),\n",
    "        showlegend=True,\n",
    "        legend=dict(\n",
    "            yanchor=\"top\",\n",
    "            y=0.99,\n",
    "            xanchor=\"right\",\n",
    "            x=0.99\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.update_yaxes(title_text=\"Average Requests\", secondary_y=False)\n",
    "    fig.update_yaxes(title_text=\"Average Latency (ms)\", secondary_y=True)\n",
    "    \n",
    "    # Save the figure\n",
    "    fig.write_image(\"daily_pattern.png\", scale=2)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_weekly_pattern(df):\n",
    "    # Add day of week\n",
    "    df['day'] = pd.to_datetime(df['timestamp']).dt.day_name()\n",
    "    \n",
    "    # Ensure days are in correct order\n",
    "    day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    \n",
    "    # Group by day and endpoint\n",
    "    weekly_stats = df.groupby(['day', 'endpoint'])['requests'].mean().reset_index()\n",
    "    \n",
    "    # Create figure\n",
    "    fig = px.line(weekly_stats, x='day', y='requests', color='endpoint',\n",
    "                  title=\"Weekly Traffic Patterns by Endpoint\",\n",
    "                  template=\"plotly_white\",\n",
    "                  height=500,\n",
    "                  width=800)\n",
    "    \n",
    "    # Customize layout\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Day of Week\",\n",
    "        yaxis_title=\"Average Requests\",\n",
    "        legend_title=\"Endpoint\",\n",
    "        font=dict(size=10),\n",
    "        xaxis={'categoryorder': 'array', 'categoryarray': day_order}\n",
    "    )\n",
    "    \n",
    "    # Save the figure\n",
    "    fig.write_image(\"weekly_pattern.png\", scale=2)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_correlation_matrix(df):\n",
    "    # Select numerical columns\n",
    "    numeric_cols = ['requests', 'latency_ms', 'error_rate', 'cpu_utilization', 'memory_utilization']\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = df[numeric_cols].corr()\n",
    "    \n",
    "    # Create heatmap\n",
    "    fig = px.imshow(corr_matrix,\n",
    "                    labels=dict(color=\"Correlation\"),\n",
    "                    color_continuous_scale=\"RdBu\",\n",
    "                    title=\"Metric Correlations\")\n",
    "    \n",
    "    fig.update_layout(\n",
    "        template=\"plotly_white\",\n",
    "        height=500,\n",
    "        width=800,\n",
    "        font=dict(size=10)\n",
    "    )\n",
    "    \n",
    "    # Save the figure\n",
    "    fig.write_image(\"correlation_matrix.png\", scale=2)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Generate all plots\n",
    "daily_fig = create_daily_pattern(df)\n",
    "weekly_fig = create_weekly_pattern(df)\n",
    "corr_fig = create_correlation_matrix(df)\n",
    "\n",
    "# Display plots in notebook\n",
    "daily_fig.show()\n",
    "weekly_fig.show()\n",
    "corr_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dbbc41-7a34-404d-8125-24b28560a621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def create_prediction_plots(df):\n",
    "    # Prepare data\n",
    "    X = df['requests'].values.reshape(-1, 1)\n",
    "    y = df['latency_ms'].values\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Fit model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Create subplots\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1,\n",
    "        subplot_titles=('Model Fit', 'Actual vs Predicted'),\n",
    "        vertical_spacing=0.15\n",
    "    )\n",
    "    \n",
    "    # Plot 1: Model Fit\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=X_train.flatten(), y=y_train, mode='markers', \n",
    "                  name='Training Data', marker=dict(color='blue', opacity=0.5)),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Add regression line\n",
    "    X_line = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)\n",
    "    y_line = model.predict(X_line)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=X_line.flatten(), y=y_line, mode='lines',\n",
    "                  name='Regression Line', line=dict(color='red')),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Plot 2: Actual vs Predicted\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=y_test, y=y_pred_test, mode='markers',\n",
    "                  name='Test Predictions', marker=dict(color='green')),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # Add perfect prediction line\n",
    "    min_val = min(y_test.min(), y_pred_test.min())\n",
    "    max_val = max(y_test.max(), y_pred_test.max())\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=[min_val, max_val], y=[min_val, max_val], mode='lines',\n",
    "                  name='Perfect Prediction', line=dict(color='black', dash='dash')),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        width=800,\n",
    "        showlegend=True,\n",
    "        title_text=\"API Performance Prediction Model\",\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "    \n",
    "    # Update axes labels\n",
    "    fig.update_xaxes(title_text=\"Requests\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Latency (ms)\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Actual Latency (ms)\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Predicted Latency (ms)\", row=2, col=1)\n",
    "    \n",
    "    # Save the figure\n",
    "    fig.write_image(\"prediction_model.png\", scale=2)\n",
    "    \n",
    "    return fig, model\n",
    "\n",
    "# Print model metrics\n",
    "def print_model_metrics(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = np.mean((y_test - y_pred) ** 2)\n",
    "    r2 = model.score(X_test, y_test)\n",
    "    \n",
    "    return {\n",
    "        'Mean Squared Error': round(mse, 2),\n",
    "        'R-squared Score': round(r2, 3),\n",
    "        'Coefficient': round(model.coef_[0], 3),\n",
    "        'Intercept': round(model.intercept_, 2)\n",
    "    }\n",
    "\n",
    "# Execute everything\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your data (assuming you've already generated it using the previous code)\n",
    "    df = pd.read_csv('api_performance_data.csv')\n",
    "    \n",
    "    # Create visualization and get model\n",
    "    fig, model = create_prediction_plots(df)\n",
    "    \n",
    "    # Get and print metrics\n",
    "    X = df['requests'].values.reshape(-1, 1)\n",
    "    y = df['latency_ms'].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    metrics = print_model_metrics(model, X_test, y_test)\n",
    "    \n",
    "    print(\"\\nModel Metrics:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
